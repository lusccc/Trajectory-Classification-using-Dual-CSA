{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import tables as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from MF_RP_mat_h5support import H5_NODE_NAME\n",
    "m = nn.Conv2d(16, 33, 3, padding=0)\n",
    "\n",
    "input = torch.randn(20,16,50,100)\n",
    "_input = input.numpy()\n",
    "out = m(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "unpool = nn.MaxUnpool2d(2, stride=2)\n",
    "input = torch.tensor([[[[ 1.,  2,  3,  4],\n",
    "                            [ 5,  6,  7,  8],\n",
    "                            [ 9, 10, 11, 12],\n",
    "                            [13, 14, 15, 16]]]])\n",
    "output, indices = pool(input)\n",
    "a=pool(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "a = torch.randn((3, 10))\n",
    "b = torch.randn((3,10))\n",
    "c = a -b\n",
    "d= c**2\n",
    "dT= d.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids(u):\n",
      "[[1 1 1 1]\n",
      " [3 3 3 3]\n",
      " [6 6 6 6]]\n",
      "---\n",
      "embs(z):\n",
      "[[[13 14 15 16]]\n",
      "\n",
      " [[17 18 19 20]]]\n",
      "---\n",
      "z_minus_u:\n",
      "[[[12 13 14 15]\n",
      "  [10 11 12 13]\n",
      "  [ 7  8  9 10]]\n",
      "\n",
      " [[16 17 18 19]\n",
      "  [14 15 16 17]\n",
      "  [11 12 13 14]]]\n",
      "---\n",
      "z_minus_u_square:\n",
      "[[[144 169 196 225]\n",
      "  [100 121 144 169]\n",
      "  [ 49  64  81 100]]\n",
      "\n",
      " [[256 289 324 361]\n",
      "  [196 225 256 289]\n",
      "  [121 144 169 196]]]\n",
      "---\n",
      "dist_square_sum:\n",
      "[[ 734  534  294]\n",
      " [1230  966  630]]\n",
      "---\n",
      "qij:\n",
      "[[0.00136054 0.00186916 0.00338983]\n",
      " [0.00081235 0.00103413 0.00158479]]\n",
      "---\n",
      "qij_sum:\n",
      "[0.00661953 0.00343126]\n",
      "---\n",
      "qij_t:\n",
      "[[0.00136054 0.00081235]\n",
      " [0.00186916 0.00103413]\n",
      " [0.00338983 0.00158479]]\n",
      "---\n",
      "qij_normalize:\n",
      "[[0.20553476 0.2367491 ]\n",
      " [0.28237018 0.3013838 ]\n",
      " [0.51209507 0.4618671 ]]\n",
      "---\n",
      "qij_normalize_t:\n",
      "[[0.20553476 0.28237018 0.51209507]\n",
      " [0.2367491  0.3013838  0.4618671 ]]\n"
     ]
    }
   ],
   "source": [
    "#***STUDENT T DISTRIBUTION TEST***\n",
    "#q_ij = 1/(1+dist(z_i, u_j)^2), then normalize it.\n",
    "centroids = np.array(\n",
    "    [[1,1,1,1],\n",
    "    [3,3,3,3],\n",
    "    [6,6,6,6]]\n",
    ") #u, 3 classes, each class centroid is 4D vector\n",
    "emb1 = np.array([[13,14,15,16],])\n",
    "emb2 = np.array([[17,18,19,20],])\n",
    "embs = np.array([emb1, emb2])#z, 2 samples, each sample embedded to 4D vector\n",
    "\n",
    "z_minus_u = embs - centroids # diff between each z and each centroids\n",
    "print('centroids(u):')\n",
    "print(centroids)\n",
    "print('---')\n",
    "print('embs(z):')\n",
    "print(embs)\n",
    "print('---')\n",
    "print('z_minus_u:')\n",
    "print(z_minus_u)\n",
    "z_minus_u_square = np.square(z_minus_u)  # i.e., distance square between each z and each centroids\n",
    "dist_square_sum = np.sum(z_minus_u_square, axis=2) # each element: square of euclid distance\n",
    "print('---')\n",
    "print('z_minus_u_square:')\n",
    "print(z_minus_u_square)\n",
    "print('---')\n",
    "print('dist_square_sum:')\n",
    "print(dist_square_sum)\n",
    "alpha = 1.\n",
    "qij = 1. / (1. + dist_square_sum / 1.) # each element: the probability of sample i belong to j\n",
    "print('---')\n",
    "print('qij:')\n",
    "print(qij)\n",
    "qij_sum = np.sum(qij, axis=1) # sum probability to all 3 centroid\n",
    "print('---')\n",
    "print('qij_sum:')\n",
    "print(qij_sum)\n",
    "qij_t = np.transpose(qij)\n",
    "print('---')\n",
    "print('qij_t:')\n",
    "print(qij_t)\n",
    "qij_normalize = qij_t / qij_sum # each probability/sum probability\n",
    "print('---')\n",
    "print('qij_normalize:')\n",
    "print(qij_normalize)\n",
    "print('---')\n",
    "print('qij_normalize_t:')\n",
    "print(qij_normalize.T) # transpose back to denote the probability of i belong to j"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([ 6.3159e-05,  1.4881e-04, -6.2440e-05])\n",
      "Std: tensor([0.9999, 0.9999, 0.9999])\n",
      "Elapsed time: 0.760 seconds\n",
      "\n",
      "Mean: tensor([ 6.3159e-05,  1.4881e-04, -6.2440e-05])\n",
      "Std: tensor([0.9999, 0.9999, 0.9999])\n",
      "Elapsed time: 0.129 seconds\n"
     ]
    }
   ],
   "source": [
    "#How to calculate the mean and std of my own dataset?\n",
    "#https://discuss.pytorch.org/t/about-normalization-using-pre-trained-vgg16-networks/23560/23\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = torch.randn(1000, 3, 224, 224)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cpu\")\n",
    "    dataset = MyDataset()\n",
    "\n",
    "    start = timeit.time.perf_counter()\n",
    "    data = dataset.data.to(device)\n",
    "    print(\"Mean:\", torch.mean(data, dim=(0, 2, 3))) # get mean on each channel for all samples\n",
    "    print(\"Std:\", torch.std(data, dim=(0, 2, 3)))\n",
    "    print(\"Elapsed time: %.3f seconds\" % (timeit.time.perf_counter() - start))\n",
    "    print()\n",
    "\n",
    "    start = timeit.time.perf_counter()\n",
    "    mean = 0.\n",
    "    for data in dataset:\n",
    "        data = data.to(device)\n",
    "        mean += torch.mean(data, dim=(1, 2))\n",
    "    mean /= len(dataset)\n",
    "    print(\"Mean:\", mean)\n",
    "\n",
    "    temp = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in dataset:\n",
    "        data = data.to(device)\n",
    "        temp += ((data.view(3, -1) - mean.unsqueeze(1)) ** 2).sum(dim=1)\n",
    "        nb_samples += np.prod(data.size()[1:])\n",
    "    std = torch.sqrt(temp/nb_samples)\n",
    "    print(\"Std:\", std)\n",
    "    print(\"Elapsed time: %.3f seconds\" % (timeit.time.perf_counter() - start))\n",
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "data_type = 'train'\n",
    "RP_mats_h5array = tb.open_file(f'./data/SHL_features/RP_mats_{data_type}.h5', mode='r').get_node('/' + H5_NODE_NAME)\n",
    "RP_mats_h5array.shape\n",
    "e=RP_mats_h5array[:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.]],\n",
      "\n",
      "        [[12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]]])\n",
      "tensor([10., 11., 12., 13.])\n",
      "tensor([[ 6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13.],\n",
      "        [14., 15., 16., 17.]])\n",
      "tensor([[ 4.,  5.,  6.,  7.],\n",
      "        [16., 17., 18., 19.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(24, dtype=torch.float).view(2,3,4)\n",
    "print(x)\n",
    "x_mean0=torch.mean(x,dim=(0,1),keepdim=False)\n",
    "x_mean1=torch.mean(x,dim=0,keepdim=False)\n",
    "x_mean2=torch.mean(x,dim=1,keepdim=False)\n",
    "print(x_mean0)\n",
    "print(x_mean1)\n",
    "print(x_mean2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}